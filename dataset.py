import os
import torch
import pandas as pd
from skimage import io, transform
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset
from pycocotools.coco import COCO
from vocabulary import create_vocabulary
from PIL import Image
import nltk
nltk.download('punkt')


class CocoDataset(Dataset):
    """ Dataset that return an image with its caption in Tensor format. """

    def __init__(self, json_path, root_dir, transform=None):
        """
        Constructor of the CocoDataset class.

        Args:
            json_path: str
                Path to the file containing the captions in json format.
            root_dir: str
                Path to the folder containing the images.
            transform: optional
                Transformation of the images.
        """
        self.coco = COCO(json_path)
        self.vocabulary, self.ids = create_vocabulary(self.coco)
        print(f"VOCABULARY LENGTH: {len(self.vocabulary)}")
        self.word_to_ix = {}
        self.id_to_word = {}
        self.root_dir = root_dir
        self.transform = transform
        self.map_vocab_to_number()

    def map_vocab_to_number(self):
        """ Method to create dictionaries to map word to index. """
        value = 0
        for word in self.vocabulary:
            self.word_to_ix[word] = value
            self.id_to_word[value] = word
            value += 1

    def __len__(self):
        """ Method to get the length of the dataset. """
        return len(list(self.coco.anns.keys()))

    def __getitem__(self, idx):
        """ Method to get each individual element of the dataset
        
        Args:
            idx: int
                fff

        Returns:
            image: Tensor
                Image in Tensor format.
            caption: Tensor
                Caption converted to numerical values.
            tokens: list
                Caption as a list of words.
        """
        if torch.is_tensor(idx):
            idx = idx.tolist()

        annotation_id = self.ids[idx]
        description = self.coco.anns[annotation_id]['caption']
        image_id = self.coco.anns[annotation_id]['image_id']
        image_name = self.coco.loadImgs(image_id)[0]['file_name']

        image_name = os.path.join(
                        self.root_dir,
                        image_name)
        image = Image.open(image_name).convert('RGB')
        image = image.resize([224, 224], Image.LANCZOS)
        # image = io.imread(image_name)
        tokens = nltk.tokenize.word_tokenize(str(description).lower())
        caption = []
        caption.append(self.word_to_ix['<start>'])
        caption.extend([self.word_to_ix[token] for token in tokens if token in self.vocabulary])
        caption.append(self.word_to_ix['<end>'])
        

        if self.transform:
            image = self.transform(image)
        caption = torch.Tensor(caption)
        # print(tokens)
        return image, caption, tokens

def generate_batch(batch):
    """ Function to convert the tuple generated by __get__item into a batch
    
    Args: 
        batch: list

    Returns:
        images: Tensor
            Image in Tensor format.
        targets: Tensor
            Caption converted to numerical values.
        descriptions: list
            Caption as a list of words.
    """
    batch.sort(key=lambda x: len(x[1]), reverse=True)
    images = [entry[0] for entry in batch]
    captions = [entry[1] for entry in batch]
    descriptions = [entry[1] for entry in batch]

    lengths = [len(cap) for cap in captions]

    targets = torch.zeros(len(captions), max(lengths)).long()
    for i, cap in enumerate(captions):
        end = lengths[i]
        targets[i, :end] = cap[:end]   

    images = torch.stack(images)

    return images, targets, descriptions

def get_data_loader(dataset, batch_size=128):
    """ Function to get the Data Loader..
    
    Args:
        dataset: CocoDataset
            Coco Dataset created previously.
        batch_size: int
            Size of the batch. 128 by default.
    
    Returns:
        data_loader: DataLoader
            Used to return the Dataset tuples in batches of predifined size
    """
    data_loader = torch.utils.data.DataLoader(dataset=dataset, 
                                              batch_size=batch_size,
                                              collate_fn=generate_batch,
                                              num_workers=2,
                                              shuffle=True)
    return data_loader
